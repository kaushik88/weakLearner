---
layout: post
mathjax: true
title: "Natural Language Processing"
tags:
- NLP
categories:
- Work
thumbnail_path: blog/personal/nlp.png
add_to_popular_list: true
---

**Core Concepts**

**Word Vectors**

**Beyond Word Vectors**

1. [Deep Averaging Networks](https://www.weak-learner.com/blog/2019/07/31/deep-averaging-networks/)
2. [BERT](https://www.weak-learner.com/blog/2019/08/16/bert/)

**Classification**

1. [Hierarchical Attention Networks](https://www.weak-learner.com/blog/2019/06/23/hierarchical_attention_networks/)

**Named Entity Recognition & Slot Filling**

1. [SUTIME: A Library for Recognizing and Normalizing Time Expressions](https://www.weak-learner.com/blog/2019/06/20/SUTime/)
2. [Named Entity Recognition with Bidirectional LSTM-CNNs](https://www.weak-learner.com/blog/2019/11/04/ner-bidirectional-lstm-cnn/)

**Conversational AI and NLU**

1. [Dialog State Tracking: A Neural Reading Comprehension Approach](https://www.weak-learner.com/blog/2019/08/19/dst-mrc/)
2. [Scalable Multi-Domain Dialogue State Tracking](https://www.weak-learner.com/blog/2019/08/20/scalable-multidomain-dst/)
3. [Dialog Context Language Modeling with Recurrent Neural Networks](https://www.weak-learner.com/blog/2019/11/01/dialog-context-language-modeling/)
4. [Effective Incorporation of Speaker Information in Utterance Encoding in Dialog](https://www.weak-learner.com/blog/2019/11/01/effective-incorporation-of-speaker-information/)
5. [Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models](https://www.weak-learner.com/blog/2019/11/03/generative-hierarchical-neural-network/)

**Machine Reading Comprehension**

1. [BiDirectional Attention Flow](https://www.weak-learner.com/blog/2019/08/13/bidirectional-attention-flow/)
2. [Dynamic Co-attention Networks](https://www.weak-learner.com/blog/2019/08/13/dynamic-coattention-network/)

**Natural Language Generation (NLG)**

1. [Attention Is All You Need](https://www.weak-learner.com/blog/2019/08/01/attention-is-all-you-need/)
2. [Blockwise Parallel Decoding for Deep Autoregressive Models](https://www.weak-learner.com/blog/2019/08/08/blockwise-parallel-decoding-for-deep-autoregressive-models/)
3. [Gmail Smart Compose: Real-Time Assisted Writing](https://www.weak-learner.com/blog/2019/11/03/gmail-smart-compose/)